<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Pretraining Large Brain Language Model for Active BCI: Silent Speech">
  <meta property="og:title" content="Pretraining Large Brain Language Model for Active BCI: Silent Speech"/>
  <meta property="og:description" content="This paper explores silent speech decoding in active brain-computer interface (BCI) systems using a novel Large Brain Language Model (LBLM) with Spectro-Temporal Predictive pretraining."/>
  <meta property="og:url" content="https://bytedance.github.io/LBLM/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/carousel1.jpg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Pretraining Large Brain Language Model for Active BCI: Silent Speech">
  <meta name="twitter:description" content="This paper explores silent speech decoding in active brain-computer interface (BCI) systems using a novel Large Brain Language Model (LBLM) with Spectro-Temporal Predictive pretraining.">
  <meta name="twitter:image" content="static/images/carousel1.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="BCI, EEG, Silent Speech, Language Model, Pretraining, Active BCI, Brain-Computer Interface">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Pretraining Large Brain Language Model for Active BCI: Silent Speech</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Pretraining Large Brain Language Model for Active BCI: Silent Speech</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="#" target="_blank">Jinzhao Zhou</a>,</span>
                <span class="author-block">
                  <a href="#" target="_blank">Yiqun Duan</a>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Jimmy Cao</a>,</span>
                  <span class="author-block">
                    <a href="#" target="_blank">Chin-Teng Lin</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">HAI-Centre, AAII, University of Technology Sydney<br></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="LBLM.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/bytedance/LBLM" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser figure-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/main_structure.png" alt="LBLM Architecture" />
      <h2 class="subtitle has-text-centered">
        Overview of the LBLM architecture, showing the Gated Conformer Backbone and Spatial Temporal Classifier components for silent speech decoding.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser figure -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This paper explores silent speech decoding in active brain-computer interface (BCI) systems, which offers more natural and flexible communication than traditional BCI applications. To overcome the reliance on external stimuli in passive BCI settings, we collected a new silent speech dataset of over 120 hours of electroencephalogram (EEG) recordings from 12 subjects, capturing 24 commonly used English words for pretraining and decoding. Following recent trend of pretraining large models with self-supervised paradigms to enhance representation learning, we propose the Large Brain Language Model (LBLM) pretrained for decoding silent speech for active BCI.
          </p>
          <p>
            To train LBLM, we propose Spectro-Temporal Predictive (STP) pretraining, a novel self-supervised approach for learning EEG representations. Unlike existing EEG pretraining in a single domain, our proposed STP method employs autoregressive modeling in the spatio-temporal domain, capturing both temporal transitions and frequency variations from the EEG signal. After pretraining, we finetune the LBLM backbone on downstream tasks, including word-level and semantic-group classification, using a spatio-temporal classifier to integrate learned representations across EEG channels.
          </p>
          <p>
            Extensive experiments demonstrate significant performance gains of LBLM over baseline models. In a challenging cross-session setting, our model achieves 42.8% accuracy in semantic classification and 39.6% in word-level classification on average, outperforming baseline methods by 4.6% and 7.3%, respectively. Our results highlight the feasibility of silent speech decoding in active BCI systems, paving the way for more natural and practical brain-to-text communications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/carousel1.jpg" alt="MEM Pretraining"/>
        <h2 class="subtitle has-text-centered">
          (A) MEM Pretraining: LBLM backbone with patching and unpatching operations for EEG representation learning.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel2.jpg" alt="STP Pretraining"/>
        <h2 class="subtitle has-text-centered">
          (B) STP Pretraining: Novel self-supervised approach capturing both temporal transitions and frequency variations.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel3.jpg" alt="Classification"/>
        <h2 class="subtitle has-text-centered">
          (C) Classification: Spatio-temporal classifier for word-level and semantic-group classification tasks.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/carousel4.jpg" alt="Masking Strategies"/>
        <h2 class="subtitle has-text-centered">
          Comparison of Random and Causal Masking strategies in MEM and STP pretraining.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
